{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a099e7e5-bc66-40d3-9867-967fa4ec32da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\ksham\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\ksham\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\ksham\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ksham\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ksham\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\ksham\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3024ab6-8ccc-4d6d-aaaf-f63a067ac55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\ksham\\anaconda3\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\ksham\\anaconda3\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\ksham\\anaconda3\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\ksham\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae32db8b-1203-4b58-8213-47d1ff7d4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "940900e0-0625-479e-8af9-62c4e2190d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ksham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ksham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3dbf1d9-fec1-435a-bcbe-70bcd52e6354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preparation\n",
    "def preprocess_text(text):\n",
    "    #tokenize the text\n",
    "    tokens=word_tokenize(text.lower())\n",
    "    #remove stopwords and puntuations\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    tokens=[word for word in tokens if word.isalpha() and word not in stop_words and word not in string.punctuation]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c92c2b50-cb17-41b9-85c5-65226cb81abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a text sample \"\n",
    "text=\"Hello, this is a sample text. I am writing this for revision. My name is Kshamita.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4a3c755-bf5e-4d10-9545-e8a5f5e2d658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ksham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47916d5e-076b-4b1f-82c0-b1ad71398b41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pass the text through the function\n",
    "tokens=preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b153c27a-077c-4930-9d87-04359e5eff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Training data\n",
    "training_data=[]\n",
    "context_size=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f66b019c-455b-4281-bfbb-ee7c46b2056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(context_size,len(tokens)-context_size):\n",
    "    context=tokens[i-context_size:i]+ tokens[i+1:i+1+context_size]\n",
    "    target=tokens[i]\n",
    "    training_data.append(context+[target])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1763abe2-ee87-465b-b338-88281019bb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hello', 'sample', 'writing', 'revision', 'text'], ['sample', 'text', 'revision', 'name', 'writing'], ['text', 'writing', 'name', 'kshamita', 'revision']]\n"
     ]
    }
   ],
   "source": [
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14974df1-0c62-43ce-8a36-707cd1c0a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cbow model definingSVWSMW\n",
    "model_cbow=Word2Vec(sentences=training_data, vector_size=500, window=context_size , sg=0, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8e54f83-f9c1-4e02-b705-813302f5037d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 105)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model training\n",
    "model_cbow.train(training_data, total_examples=len(training_data),epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a81bb23-35bc-4bc2-bca7-b84445e3bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction data\n",
    "prev_words=[\"hello\",\"sample\"]\n",
    "late_words=[\"revision\",\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c09ebd8-3412-4232-adfe-f8ee3a807552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Target word is:[('writing', 0.14285736)]\n"
     ]
    }
   ],
   "source": [
    "#Generate Output\n",
    "pred = model_cbow.predict_output_word(prev_words+late_words,topn=1)\n",
    "print(f\"The Target word is:{pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2d21d-cd11-4ad6-b16d-a8446e4b02ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
